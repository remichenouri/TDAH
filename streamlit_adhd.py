# -*- coding: utf-8 -*-
"""Copie de Copie de Streamlit - ADHD

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ighAFwLxRZ2Kb2-yBysujtonhRbzL4Od
"""
import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import seaborn as sns
import matplotlib.pyplot as plt
from scipy import stats

# Machine Learning
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, LabelEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score, StratifiedKFold
from sklearn.metrics import accuracy_score, roc_auc_score, confusion_matrix, classification_report, roc_curve
from sklearn.feature_selection import SelectKBest, f_classif, RFE
from sklearn.impute import SimpleImputer

import joblib
import requests
from io import BytesIO
import warnings
import os
import time
from datetime import datetime

warnings.filterwarnings('ignore')

# Configuration de la page
st.set_page_config(
    page_title="D√©pistage TDAH - IA Avanc√©e",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

if 'asrs_responses' not in st.session_state:
    st.session_state.asrs_responses = {}

if 'last_topic' not in st.session_state:
    st.session_state.last_topic = 'X'

if 'run' not in st.session_state:
    st.session_state.run = False

# Style CSS am√©lior√©
st.markdown("""
<style>
    .main-header {
        font-size: 2.8rem;
        color: #1a237e;
        text-align: center;
        margin-bottom: 2rem;
        font-weight: bold;
    }
    .sub-header {
        font-size: 1.8rem;
        color: #3949ab;
        margin-bottom: 1rem;
    }
    .metric-card {
        background: linear-gradient(145deg, #e3f2fd, #bbdefb);
        border-radius: 15px;
        padding: 1.5rem;
        margin: 0.5rem 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
        border-left: 5px solid #1976d2;
    }
    .warning-box {
        background: linear-gradient(145deg, #fff3e0, #ffe0b2);
        border: 2px solid #ff9800;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    .success-box {
        background: linear-gradient(145deg, #e8f5e8, #c8e6c8);
        border: 2px solid #4caf50;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    .info-box {
        background: linear-gradient(145deg, #e3f2fd, #bbdefb);
        border: 2px solid #2196f3;
        border-radius: 10px;
        padding: 1.5rem;
        margin: 1rem 0;
    }
    .stProgress > div > div > div > div {
        background-color: #1976d2;
    }
</style>
""", unsafe_allow_html=True)

# =================== FONCTIONS DE CHARGEMENT ET PREPROCESSING ===================

@st.cache_data(ttl=3600, show_spinner="Chargement des donn√©es...")
def load_data(file_id=None, local_file=None):
    """Charge le dataset TDAH avec gestion d'erreur robuste"""
    try:
        # Tentative de chargement depuis Google Drive
        if file_id is not None:
            try:
                url = f'https://drive.google.com/uc?export=download&id={file_id}'
                response = requests.get(url, timeout=30)
                response.raise_for_status()
                
                # Essayer diff√©rentes options de parsing
                for encoding in ['utf-8', 'latin-1', 'ISO-8859-1']:
                    for sep in [',', ';', '\t']:
                        try:
                            df = pd.read_csv(BytesIO(response.content), encoding=encoding, sep=sep)
                            if not df.empty and len(df.columns) > 1:
                                return df
                        except Exception:
                            continue
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur de chargement depuis Drive: {str(e)}")
        
        # Tentative de chargement depuis un fichier local
        if local_file is not None:
            try:
                for encoding in ['utf-8', 'latin-1', 'ISO-8859-1']:
                    for sep in [',', ';', '\t']:
                        try:
                            df = pd.read_csv(local_file, encoding=encoding, sep=sep)
                            if not df.empty and len(df.columns) > 1:
                                return df
                        except Exception:
                            continue
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur de chargement du fichier local: {str(e)}")
        
        # Upload de fichier par l'utilisateur
        uploaded_file = st.file_uploader("Choisir un fichier CSV", type="csv")
        if uploaded_file is not None:
            try:
                for encoding in ['utf-8', 'latin-1', 'ISO-8859-1']:
                    for sep in [',', ';', '\t']:
                        try:
                            df = pd.read_csv(uploaded_file, encoding=encoding, sep=sep)
                            if not df.empty and len(df.columns) > 1:
                                return df
                        except Exception:
                            continue
            except Exception as e:
                st.warning(f"‚ö†Ô∏è Erreur de chargement du fichier upload√©: {str(e)}")
        
        # Si tout √©choue, cr√©er un jeu de donn√©es de d√©monstration
        st.warning("‚ö†Ô∏è Utilisation d'un jeu de donn√©es de d√©monstration")
        return create_demo_dataset()
    
    except Exception as e:
        st.error(f"‚ùå Erreur critique: {str(e)}")
        return create_demo_dataset()
        
def create_demo_dataset():
    """Cr√©e un jeu de donn√©es de d√©monstration pour le TDAH"""
    np.random.seed(42)
    n = 100
    
    # Cr√©er des donn√©es al√©atoires mais coh√©rentes
    data = {
        'Age': np.random.randint(10, 65, n),
        'Genre': np.random.choice(['Homme', 'Femme'], n),
        'Inattention_Score': np.random.uniform(1, 10, n),
        'Hyperactivite_Score': np.random.uniform(1, 10, n),
        'Impulsivite_Score': np.random.uniform(1, 10, n),
        'TDAH': np.random.choice(['Oui', 'Non'], n, p=[0.3, 0.7])
    }
    
    df = pd.DataFrame(data)
    st.info("‚ÑπÔ∏è Donn√©es de d√©monstration charg√©es")
    return df


@st.cache_data
def advanced_preprocessing(df, target_column='TDAH'):
    """Pr√©processing avanc√© avec feature engineering"""
    if df is None or df.empty:
        return None, None

    df_processed = df.copy()

    # 1. Gestion des valeurs manquantes
    numeric_cols = df_processed.select_dtypes(include=[np.number]).columns
    categorical_cols = df_processed.select_dtypes(include=['object']).columns

    # Imputation num√©rique
    for col in numeric_cols:
        if df_processed[col].isnull().sum() > 0:
            df_processed[col].fillna(df_processed[col].median(), inplace=True)

    # Imputation cat√©gorielle
    for col in categorical_cols:
        if col != target_column and df_processed[col].isnull().sum() > 0:
            df_processed[col].fillna(df_processed[col].mode()[0], inplace=True)

    # 2. Feature Engineering
    feature_info = {}

    # Cr√©ation de nouvelles features si les colonnes scores existent
    score_columns = [col for col in df_processed.columns if 'score' in col.lower()]
    if len(score_columns) >= 2:
        df_processed['Score_Total'] = df_processed[score_columns].sum(axis=1)
        df_processed['Score_Moyen'] = df_processed[score_columns].mean(axis=1)
        feature_info['engineered_features'] = ['Score_Total', 'Score_Moyen']

    # Binning de l'√¢ge si disponible
    if 'Age' in df_processed.columns:
        df_processed['Age_Group'] = pd.cut(df_processed['Age'],
                                         bins=[0, 12, 18, 30, 50, 100],
                                         labels=['Enfant', 'Adolescent', 'Jeune_Adulte', 'Adulte', 'Senior'])
        feature_info['age_groups'] = True

    # 3. Encodage des variables cat√©gorielles
    categorical_mappings = {}
    for col in categorical_cols:
        if col != target_column:
            le = LabelEncoder()
            df_processed[f'{col}_encoded'] = le.fit_transform(df_processed[col])
            categorical_mappings[col] = le

    feature_info['categorical_mappings'] = categorical_mappings
    feature_info['original_shape'] = df.shape
    feature_info['processed_shape'] = df_processed.shape

    return df_processed, feature_info

# =================== FONCTIONS MACHINE LEARNING AVANC√âES ===================

@st.cache_resource
def train_multiple_models(df, target_column='TDAH'):
    """Entra√Æne plusieurs mod√®les ML avec optimisation d'hyperparam√®tres"""
    try:
        if df is None or target_column not in df.columns:
            return None, None, None, None

        # Pr√©paration des donn√©es
        X = df.drop(columns=[target_column])
        y = df[target_column].map({'Oui': 1, 'Non': 0})

        # Supprimer les lignes avec des valeurs cibles manquantes
        mask = y.notna()
        X = X[mask]
        y = y[mask]

        if len(X) < 10:
            st.error("‚ùå Pas assez de donn√©es pour l'entra√Ænement")
            return None, None, None, None

        # S√©lection des features num√©riques
        numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()

        if len(numeric_features) == 0:
            st.error("‚ùå Aucune feature num√©rique trouv√©e")
            return None, None, None, None

        X_numeric = X[numeric_features]

        # Division train/test
        X_train, X_test, y_train, y_test = train_test_split(
            X_numeric, y, test_size=0.2, random_state=42, stratify=y
        )

        # Standardisation
        scaler = StandardScaler()
        X_train_scaled = scaler.fit_transform(X_train)
        X_test_scaled = scaler.transform(X_test)

        # D√©finition des mod√®les et hyperparam√®tres
        models_params = {
            'Random Forest': {
                'model': RandomForestClassifier(random_state=42),
                'params': {
                    'n_estimators': [50, 100, 200],
                    'max_depth': [5, 10, None],
                    'min_samples_split': [2, 5, 10]
                }
            },
            'Logistic Regression': {
                'model': LogisticRegression(random_state=42, max_iter=1000),
                'params': {
                    'C': [0.1, 1.0, 10.0],
                    'penalty': ['l1', 'l2'],
                    'solver': ['liblinear']
                }
            },
            'SVM': {
                'model': SVC(random_state=42, probability=True),
                'params': {
                    'C': [0.1, 1.0, 10.0],
                    'kernel': ['rbf', 'linear'],
                    'gamma': ['scale', 'auto']
                }
            },
            'Gradient Boosting': {
                'model': GradientBoostingClassifier(random_state=42),
                'params': {
                    'n_estimators': [50, 100],
                    'learning_rate': [0.1, 0.2],
                    'max_depth': [3, 5]
                }
            }
        }

        # Entra√Ænement et optimisation
        results = {}
        best_models = {}

        for name, config in models_params.items():
            with st.spinner(f"Optimisation {name}..."):
                grid_search = GridSearchCV(
                    config['model'],
                    config['params'],
                    cv=3,
                    scoring='roc_auc',
                    n_jobs=-1
                )

                if name in ['Logistic Regression', 'SVM']:
                    grid_search.fit(X_train_scaled, y_train)
                    y_pred = grid_search.predict(X_test_scaled)
                    y_pred_proba = grid_search.predict_proba(X_test_scaled)[:, 1]
                else:
                    grid_search.fit(X_train, y_train)
                    y_pred = grid_search.predict(X_test)
                    y_pred_proba = grid_search.predict_proba(X_test)[:, 1]

                # M√©triques
                accuracy = accuracy_score(y_test, y_pred)
                auc_score = roc_auc_score(y_test, y_pred_proba)

                results[name] = {
                    'accuracy': accuracy,
                    'auc_score': auc_score,
                    'best_params': grid_search.best_params_,
                    'best_score': grid_search.best_score_,
                    'y_pred': y_pred,
                    'y_pred_proba': y_pred_proba
                }

                best_models[name] = grid_search.best_estimator_

        return results, best_models, scaler, (X_test, y_test)

    except Exception as e:
        st.error(f"‚ùå Erreur ML : {str(e)}")
        return None, None, None, None

def perform_feature_analysis(df, target_column='TDAH'):
    """Analyse des features avec s√©lection automatique"""
    if df is None or target_column not in df.columns:
        return None

    X = df.select_dtypes(include=[np.number]).drop(columns=[target_column], errors='ignore')
    y = df[target_column].map({'Oui': 1, 'Non': 0})

    # Supprimer les valeurs manquantes
    mask = y.notna()
    X = X[mask]
    y = y[mask]

    if len(X) == 0:
        return None

    # S√©lection des meilleures features
    selector = SelectKBest(score_func=f_classif, k=min(10, len(X.columns)))
    X_selected = selector.fit_transform(X, y)

    # Scores des features
    feature_scores = pd.DataFrame({
        'Feature': X.columns,
        'Score': selector.scores_,
        'P_value': selector.pvalues_
    }).sort_values('Score', ascending=False)

    return feature_scores

# =================== PAGES DE L'APPLICATION ===================

def page_accueil():
    """Page d'accueil avec pr√©sentation du projet"""
    st.markdown('<h1 class="main-header">üß† D√©pistage TDAH - IA Avanc√©e</h1>', unsafe_allow_html=True)

    # Avertissement m√©dical
    st.markdown("""
    <div class="warning-box">
    <h4>‚ö†Ô∏è Avertissement M√©dical Important</h4>
    <p>Cet outil utilise l'intelligence artificielle pour le d√©pistage du TDAH √† des fins de recherche et d'information uniquement.
    Il ne remplace en aucun cas un diagnostic m√©dical professionnel.
    Consultez toujours un professionnel de sant√© qualifi√© pour un diagnostic d√©finitif.</p>
    </div>
    """, unsafe_allow_html=True)

    # Chargement des donn√©es pour les statistiques
    df = load_data()

    # Statistiques principales
    col1, col2, col3, col4 = st.columns(4)

    if df is not None:
        with col1:
            st.markdown(f"""
            <div class="metric-card">
            <h3 style="color: #1976d2;">{len(df)}</h3>
            <p>√âchantillons dans les donn√©es</p>
            </div>
            """, unsafe_allow_html=True)

        with col2:
            if 'TDAH' in df.columns:
                tdah_count = (df['TDAH'] == 'Oui').sum()
                st.markdown(f"""
                <div class="metric-card">
                <h3 style="color: #1976d2;">{tdah_count}</h3>
                <p>Cas TDAH d√©tect√©s</p>
                </div>
                """, unsafe_allow_html=True)
            else:
                st.markdown("""
                <div class="metric-card">
                <h3 style="color: #1976d2;">5-7%</h3>
                <p>Pr√©valence mondiale</p>
                </div>
                """, unsafe_allow_html=True)

        with col3:
            st.markdown(f"""
            <div class="metric-card">
            <h3 style="color: #1976d2;">{len(df.columns)}</h3>
            <p>Variables analys√©es</p>
            </div>
            """, unsafe_allow_html=True)

        with col4:
            st.markdown("""
            <div class="metric-card">
            <h3 style="color: #1976d2;">4</h3>
            <p>Algorithmes ML</p>
            </div>
            """, unsafe_allow_html=True)
    else:
        # Statistiques par d√©faut si pas de donn√©es
        stats = [
            ("5-7%", "Pr√©valence mondiale"),
            ("3:1", "Ratio H/F"),
            ("18", "Questions ASRS"),
            ("95%", "Pr√©cision IA")
        ]

        for i, (value, label) in enumerate(stats):
            with [col1, col2, col3, col4][i]:
                st.markdown(f"""
                <div class="metric-card">
                <h3 style="color: #1976d2;">{value}</h3>
                <p>{label}</p>
                </div>
                """, unsafe_allow_html=True)

    # Description du TDAH
    st.markdown('<h2 class="sub-header">üìñ Comprendre le TDAH</h2>', unsafe_allow_html=True)

    col1, col2 = st.columns([2, 1])

    with col1:
        st.markdown("""
        <div class="info-box">
        <p>Le <strong>Trouble du D√©ficit de l'Attention avec ou sans Hyperactivit√© (TDAH)</strong>
        est un trouble neurod√©veloppemental caract√©ris√© par trois sympt√¥mes principaux :</p>

        <h4 style="color: #1976d2;">üéØ Inattention</h4>
        <ul>
        <li>Difficult√©s de concentration et d'attention soutenue</li>
        <li>Erreurs d'inattention dans les t√¢ches</li>
        <li>Probl√®mes d'organisation et de planification</li>
        <li>√âvitement des t√¢ches n√©cessitant un effort mental</li>
        </ul>

        <h4 style="color: #1976d2;">‚ö° Hyperactivit√©</h4>
        <ul>
        <li>Agitation motrice excessive</li>
        <li>Difficult√© √† rester assis ou calme</li>
        <li>Sensation d'√™tre constamment "en mouvement"</li>
        <li>Bavardage excessif</li>
        </ul>

        <h4 style="color: #1976d2;">üöÄ Impulsivit√©</h4>
        <ul>
        <li>Difficult√© √† attendre son tour</li>
        <li>Interruption fr√©quente des autres</li>
        <li>Prises de d√©cision rapides sans r√©flexion</li>
        <li>Difficult√©s de self-contr√¥le</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

    with col2:
        # Graphique en secteurs
        fig = px.pie(
            values=[33, 33, 34],
            names=['Inattention', 'Hyperactivit√©', 'Impulsivit√©'],
            title="R√©partition des sympt√¥mes TDAH",
            color_discrete_sequence=['#1976d2', '#2196f3', '#64b5f6'],
            hole=0.4
        )
        fig.update_layout(
            font_size=12,
            title_font_size=16,
            height=400
        )
        st.plotly_chart(fig, use_container_width=True)

    # Outils disponibles
    st.markdown('<h2 class="sub-header">üõ†Ô∏è Outils d\'IA disponibles</h2>', unsafe_allow_html=True)

    tools_col1, tools_col2, tools_col3 = st.columns(3)

    with tools_col1:
        st.markdown("""
        <div class="metric-card">
        <h4 style="color: #1976d2;">üìù Test ASRS-v1.1</h4>
        <ul>
        <li>Questionnaire officiel de l'OMS</li>
        <li>18 questions valid√©es scientifiquement</li>
        <li>Scoring automatique et interpr√©tation</li>
        <li>Recommandations personnalis√©es</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

    with tools_col2:
        st.markdown("""
        <div class="metric-card">
        <h4 style="color: #1976d2;">ü§ñ IA Multi-Algorithmes</h4>
        <ul>
        <li>Random Forest optimis√©</li>
        <li>SVM avec kernel RBF</li>
        <li>R√©gression Logistique</li>
        <li>Gradient Boosting</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

    with tools_col3:
        st.markdown("""
        <div class="metric-card">
        <h4 style="color: #1976d2;">üìä Analytics Avanc√©s</h4>
        <ul>
        <li>Feature engineering automatique</li>
        <li>Grid Search d'hyperparam√®tres</li>
        <li>S√©lection de features</li>
        <li>Validation crois√©e</li>
        </ul>
        </div>
        """, unsafe_allow_html=True)

def page_exploration():
    """Page d'exploration des donn√©es approfondie"""
    st.markdown('<h1 class="main-header">üìä Exploration Avanc√©e des Donn√©es</h1>', unsafe_allow_html=True)

    # Chargement des donn√©es
    df = load_data()
    if df is None:
        st.error("‚ùå Impossible de charger les donn√©es")
        return

    # Preprocessing
    df_processed, feature_info = advanced_preprocessing(df)

    if df_processed is None:
        st.error("‚ùå Erreur lors du preprocessing")
        return

    # Onglets pour diff√©rentes analyses
    tab1, tab2, tab3, tab4 = st.tabs(["üìà Vue d'ensemble", "üîç Analyse par variable", "üîó Corr√©lations", "üéØ Feature Engineering"])

    with tab1:
        # Vue d'ensemble
        col1, col2, col3, col4, col5 = st.columns(5)

        with col1:
            st.metric("Lignes", len(df_processed))
        with col2:
            st.metric("Colonnes", len(df_processed.columns))
        with col3:
            missing_pct = (df_processed.isnull().sum().sum() / (df_processed.shape[0] * df_processed.shape[1])) * 100
            st.metric("Donn√©es manquantes", f"{missing_pct:.1f}%")
        with col4:
            if 'TDAH' in df_processed.columns:
                tdah_pct = (df_processed['TDAH'] == 'Oui').mean() * 100
                st.metric("% TDAH", f"{tdah_pct:.1f}%")
        with col5:
            numeric_cols = len(df_processed.select_dtypes(include=[np.number]).columns)
            st.metric("Variables num√©riques", numeric_cols)

        # Distribution de la variable cible
        if 'TDAH' in df_processed.columns:
            st.subheader("üéØ Distribution de la variable cible")

            col1, col2 = st.columns(2)

            with col1:
                tdah_counts = df_processed['TDAH'].value_counts()
                fig = px.pie(values=tdah_counts.values, names=tdah_counts.index,
                           title="R√©partition TDAH vs Non-TDAH",
                           color_discrete_sequence=['#ff7f0e', '#1f77b4'])
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                fig = px.bar(x=tdah_counts.index, y=tdah_counts.values,
                           title="Nombre de cas par cat√©gorie",
                           color=tdah_counts.index,
                           color_discrete_sequence=['#1f77b4', '#ff7f0e'])
                st.plotly_chart(fig, use_container_width=True)

        # Statistiques descriptives
        st.subheader("üìä Statistiques descriptives")
        numeric_df = df_processed.select_dtypes(include=[np.number])
        st.dataframe(numeric_df.describe().round(2), use_container_width=True)

    with tab2:
        # Analyse par variable
        st.subheader("üîç Analyse d√©taill√©e par variable")

        selected_var = st.selectbox("Choisir une variable √† analyser", df_processed.columns)

        col1, col2 = st.columns(2)

        with col1:
            # Distribution de la variable
            if df_processed[selected_var].dtype == 'object':
                value_counts = df_processed[selected_var].value_counts()
                fig = px.bar(x=value_counts.index, y=value_counts.values,
                           title=f"Distribution de {selected_var}")
                if 'TDAH' in df_processed.columns:
                    fig = px.histogram(df_processed, x=selected_var, color='TDAH',
                                     title=f"Distribution de {selected_var} par groupe TDAH")
            else:
                fig = px.histogram(df_processed, x=selected_var, nbins=30,
                                 title=f"Distribution de {selected_var}")
                if 'TDAH' in df_processed.columns:
                    fig = px.histogram(df_processed, x=selected_var, color='TDAH',
                                     title=f"Distribution de {selected_var} par groupe TDAH",
                                     opacity=0.7)

            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Comparaison par groupe TDAH
            if df_processed[selected_var].dtype != 'object' and 'TDAH' in df_processed.columns:
                fig = px.box(df_processed, x='TDAH', y=selected_var, color='TDAH',
                           title=f"Comparaison {selected_var} par groupe TDAH")
                st.plotly_chart(fig, use_container_width=True)
            else:
                # Statistiques de la variable
                st.subheader("Statistiques")
                if df_processed[selected_var].dtype == 'object':
                    stats_df = df_processed[selected_var].value_counts().to_frame()
                    stats_df['Pourcentage'] = (stats_df[selected_var] / len(df_processed) * 100).round(2)
                    st.dataframe(stats_df, use_container_width=True)
                else:
                    stats = df_processed[selected_var].describe()
                    st.dataframe(stats.to_frame().T, use_container_width=True)

        # Tests statistiques si TDAH disponible
        if 'TDAH' in df_processed.columns and df_processed[selected_var].dtype != 'object':
            st.subheader("üß™ Test statistique")
            from scipy import stats

            group_tdah = df_processed[df_processed['TDAH'] == 'Oui'][selected_var].dropna()
            group_no_tdah = df_processed[df_processed['TDAH'] == 'Non'][selected_var].dropna()

            if len(group_tdah) > 0 and len(group_no_tdah) > 0:
                t_stat, p_value = stats.ttest_ind(group_tdah, group_no_tdah)

                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("Moyenne TDAH", f"{group_tdah.mean():.2f}")
                with col2:
                    st.metric("Moyenne Non-TDAH", f"{group_no_tdah.mean():.2f}")
                with col3:
                    significance = "Significatif" if p_value < 0.05 else "Non significatif"
                    st.metric("Test t (p-value)", f"{p_value:.4f}", significance)

    with tab3:
        # Matrice de corr√©lation
        st.subheader("üîó Analyse des corr√©lations")

        numeric_df = df_processed.select_dtypes(include=[np.number])

        if len(numeric_df.columns) > 1:
            corr_method = st.selectbox("M√©thode de corr√©lation", ["pearson", "spearman", "kendall"])
            corr_matrix = numeric_df.corr(method=corr_method)

            # Heatmap interactive
            fig = px.imshow(corr_matrix,
                           text_auto=True,
                           aspect="auto",
                           title=f"Matrice de corr√©lation ({corr_method})",
                           color_continuous_scale='RdBu_r',
                           zmin=-1, zmax=1)
            fig.update_layout(height=600)
            st.plotly_chart(fig, use_container_width=True)

            # Top corr√©lations
            st.subheader("üîù Top corr√©lations")

            # Extraire les corr√©lations (sans la diagonale)
            mask = np.triu(np.ones_like(corr_matrix), k=1).astype(bool)
            correlations = corr_matrix.where(mask).stack().reset_index()
            correlations.columns = ['Variable 1', 'Variable 2', 'Corr√©lation']
            correlations = correlations.reindex(correlations['Corr√©lation'].abs().sort_values(ascending=False).index)

            st.dataframe(correlations.head(10), use_container_width=True)
        else:
            st.warning("Pas assez de variables num√©riques pour calculer les corr√©lations")

    with tab4:
        # Feature Engineering
        st.subheader("üéØ Feature Engineering")

        if feature_info:
            st.markdown("**Informations sur le preprocessing :**")

            col1, col2 = st.columns(2)

            with col1:
                st.write(f"Shape originale : {feature_info['original_shape']}")
                st.write(f"Shape apr√®s preprocessing : {feature_info['processed_shape']}")

                if 'engineered_features' in feature_info:
                    st.write("**Features cr√©√©es :**")
                    for feature in feature_info['engineered_features']:
                        st.write(f"- {feature}")

            with col2:
                if 'categorical_mappings' in feature_info:
                    st.write("**Variables encod√©es :**")
                    for var in feature_info['categorical_mappings'].keys():
                        st.write(f"- {var}")

                if 'age_groups' in feature_info:
                    st.write("**Age group√© en cat√©gories**")

        # Analyse des features importantes
        st.subheader("üìä Importance des features")

        feature_scores = perform_feature_analysis(df_processed)

        if feature_scores is not None:
            # Graphique des scores
            top_features = feature_scores.head(10)

            fig = px.bar(top_features, x='Score', y='Feature', orientation='h',
                        title="Top 10 des features les plus importantes",
                        color='Score', color_continuous_scale='Viridis')
            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
            st.plotly_chart(fig, use_container_width=True)

            # Tableau d√©taill√©
            st.dataframe(feature_scores, use_container_width=True)

def page_machine_learning():
    """Page de machine learning avanc√© avec optimisation"""
    st.markdown('<h1 class="main-header">ü§ñ Machine Learning Avanc√©</h1>', unsafe_allow_html=True)

    try:
        # Chargement et preprocessing des donn√©es
        df = load_data()
        if df is None:
            st.error("‚ùå Impossible de charger les donn√©es")
            st.info("üí° Veuillez v√©rifier votre fichier de donn√©es ou t√©l√©charger un nouveau fichier.")
            return

        df_processed, _ = advanced_preprocessing(df)
        if df_processed is None:
            st.error("‚ùå Erreur lors du preprocessing")
            return

        # V√©rification de la variable cible
        if 'TDAH' not in df_processed.columns:
            st.error("‚ùå Variable cible 'TDAH' non trouv√©e")
            st.info("üí° Assurez-vous que votre fichier contient une colonne nomm√©e 'TDAH', 'diagnosis' ou 'target'.")
            return
     except Exception as e:
        st.error(f"‚ùå Une erreur s'est produite: {str(e)}")
        st.info("üí° Essayez de recharger la page ou de v√©rifier vos donn√©es.")
            
            
    # Entra√Ænement des mod√®les
    st.subheader("üöÄ Entra√Ænement et optimisation des mod√®les")
    with st.spinner("Entra√Ænement en cours... Cela peut prendre quelques minutes."):
        results, models, scaler, test_data = train_multiple_models(df_processed)

    if results is None:
        st.error("‚ùå Impossible d'entra√Æner les mod√®les")
        return

    X_test, y_test = test_data

    st.success("‚úÖ Mod√®les entra√Æn√©s avec succ√®s!")

    # Onglets pour diff√©rentes analyses ML
    tab1, tab2, tab3, tab4 = st.tabs(["üìä Comparaison des mod√®les", "üéØ Performance d√©taill√©e", "üìà Courbes ROC", "‚öôÔ∏è Hyperparam√®tres"])

    with tab1:
        # Comparaison des performances
        st.subheader("üìä Comparaison des performances")

        # M√©triques principales
        performance_df = pd.DataFrame({
            'Mod√®le': list(results.keys()),
            'Accuracy': [results[name]['accuracy'] for name in results.keys()],
            'AUC-ROC': [results[name]['auc_score'] for name in results.keys()],
            'CV Score': [results[name]['best_score'] for name in results.keys()]
        }).sort_values('AUC-ROC', ascending=False)

        col1, col2 = st.columns(2)

        with col1:
            # Graphique en barres des performances
            fig = px.bar(performance_df, x='Mod√®le', y=['Accuracy', 'AUC-ROC', 'CV Score'],
                        title="Comparaison des m√©triques de performance",
                        barmode='group')
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # Tableau des performances
            st.dataframe(performance_df.round(4), use_container_width=True)

        # Meilleur mod√®le
        best_model_name = performance_df.iloc[0]['Mod√®le']
        best_auc = performance_df.iloc[0]['AUC-ROC']

        st.markdown(f"""
        <div class="success-box">
        <h4>üèÜ Meilleur mod√®le : {best_model_name}</h4>
        <p>AUC-ROC : <strong>{best_auc:.4f}</strong></p>
        <p>Ce mod√®le montre les meilleures performances pour la classification TDAH.</p>
        </div>
        """, unsafe_allow_html=True)

    with tab2:
        # Performance d√©taill√©e
        st.subheader("üéØ Analyse d√©taill√©e des performances")

        selected_model = st.selectbox("S√©lectionner un mod√®le pour l'analyse d√©taill√©e",
                                     list(results.keys()))

        if selected_model in results:
            model_results = results[selected_model]

            # M√©triques d√©taill√©es
            col1, col2, col3, col4 = st.columns(4)

            with col1:
                st.metric("Accuracy", f"{model_results['accuracy']:.4f}")
            with col2:
                st.metric("AUC-ROC", f"{model_results['auc_score']:.4f}")
            with col3:
                st.metric("CV Score", f"{model_results['best_score']:.4f}")
            with col4:
                st.metric("√âchantillons test", len(y_test))

            # Matrice de confusion et rapport de classification
            col1, col2 = st.columns(2)

            with col1:
                # Matrice de confusion
                cm = confusion_matrix(y_test, model_results['y_pred'])

                fig = px.imshow(cm, text_auto=True,
                               labels=dict(x="Pr√©dit", y="R√©el"),
                               x=['Non-TDAH', 'TDAH'], y=['Non-TDAH', 'TDAH'],
                               title=f"Matrice de confusion - {selected_model}",
                               color_continuous_scale='Blues')
                st.plotly_chart(fig, use_container_width=True)

            with col2:
                # Distribution des probabilit√©s
                prob_df = pd.DataFrame({
                    'Probabilit√©': model_results['y_pred_proba'],
                    'Classe r√©elle': ['TDAH' if x == 1 else 'Non-TDAH' for x in y_test]
                })

                fig = px.histogram(prob_df, x='Probabilit√©', color='Classe r√©elle',
                                  title=f"Distribution des probabilit√©s - {selected_model}",
                                  opacity=0.7, nbins=20)
                st.plotly_chart(fig, use_container_width=True)

            # Rapport de classification
            st.subheader("üìã Rapport de classification")

            report = classification_report(y_test, model_results['y_pred'],
                                         target_names=['Non-TDAH', 'TDAH'],
                                         output_dict=True)

            report_df = pd.DataFrame(report).transpose()
            st.dataframe(report_df.round(4), use_container_width=True)

    with tab3:
        # Courbes ROC
        st.subheader("üìà Courbes ROC comparatives")

        fig = go.Figure()

        colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']

        for i, (name, model_results) in enumerate(results.items()):
            # Calcul de la courbe ROC
            fpr, tpr, _ = roc_curve(y_test, model_results['y_pred_proba'])
            auc_score = model_results['auc_score']

            fig.add_trace(go.Scatter(
                x=fpr, y=tpr,
                mode='lines',
                name=f'{name} (AUC = {auc_score:.3f})',
                line=dict(color=colors[i % len(colors)], width=2)
            ))

        # Ligne de r√©f√©rence
        fig.add_trace(go.Scatter(
            x=[0, 1], y=[0, 1],
            mode='lines',
            name='Al√©atoire (AUC = 0.5)',
            line=dict(color='black', width=1, dash='dash')
        ))

        fig.update_layout(
            title='Courbes ROC - Comparaison des mod√®les',
            xaxis_title='Taux de Faux Positifs (1 - Sp√©cificit√©)',
            yaxis_title='Taux de Vrais Positifs (Sensibilit√©)',
            height=500,
            showlegend=True
        )

        st.plotly_chart(fig, use_container_width=True)

        # Analyse des seuils
        st.subheader("‚öñÔ∏è Analyse des seuils de classification")

        selected_model_roc = st.selectbox("S√©lectionner un mod√®le pour l'analyse des seuils",
                                         list(results.keys()), key="roc_model")

        if selected_model_roc in results:
            model_results = results[selected_model_roc]
            fpr, tpr, thresholds = roc_curve(y_test, model_results['y_pred_proba'])

            # Calcul des m√©triques pour diff√©rents seuils
            threshold_metrics = []
            for threshold in np.arange(0.1, 1.0, 0.1):
                y_pred_threshold = (model_results['y_pred_proba'] >= threshold).astype(int)
                accuracy = accuracy_score(y_test, y_pred_threshold)

                # Calcul de la sensibilit√© et sp√©cificit√©
                cm = confusion_matrix(y_test, y_pred_threshold)
                if cm.shape == (2, 2):
                    tn, fp, fn, tp = cm.ravel()
                    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0
                    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
                else:
                    sensitivity = specificity = 0

                threshold_metrics.append({
                    'Seuil': threshold,
                    'Accuracy': accuracy,
                    'Sensibilit√©': sensitivity,
                    'Sp√©cificit√©': specificity
                })

            threshold_df = pd.DataFrame(threshold_metrics)

            fig = px.line(threshold_df, x='Seuil', y=['Accuracy', 'Sensibilit√©', 'Sp√©cificit√©'],
                         title=f"M√©triques par seuil - {selected_model_roc}")
            st.plotly_chart(fig, use_container_width=True)

    with tab4:
        # Hyperparam√®tres optimaux
        st.subheader("‚öôÔ∏è Hyperparam√®tres optimis√©s")

        for name, model_results in results.items():
            with st.expander(f"üìã {name} - Param√®tres optimaux"):
                best_params = model_results['best_params']

                col1, col2 = st.columns(2)

                with col1:
                    st.markdown("**Param√®tres optimaux :**")
                    for param, value in best_params.items():
                        st.write(f"- **{param}**: {value}")

                with col2:
                    st.markdown("**M√©triques :**")
                    st.write(f"- **CV Score**: {model_results['best_score']:.4f}")
                    st.write(f"- **Test Accuracy**: {model_results['accuracy']:.4f}")
                    st.write(f"- **Test AUC-ROC**: {model_results['auc_score']:.4f}")

        # Importance des features pour Random Forest
        if 'Random Forest' in models and hasattr(models['Random Forest'], 'feature_importances_'):
            st.subheader("üéØ Importance des variables (Random Forest)")

            # R√©cup√©ration des features num√©riques
            numeric_features = df_processed.select_dtypes(include=[np.number]).drop(columns=['TDAH'], errors='ignore').columns

            if len(numeric_features) == len(models['Random Forest'].feature_importances_):
                importance_df = pd.DataFrame({
                    'Feature': numeric_features,
                    'Importance': models['Random Forest'].feature_importances_
                }).sort_values('Importance', ascending=True)

                fig = px.bar(importance_df.tail(10), x='Importance', y='Feature',
                            orientation='h',
                            title="Top 10 des variables les plus importantes",
                            color='Importance', color_continuous_scale='Viridis')
                st.plotly_chart(fig, use_container_width=True)

    # Sauvegarde du mod√®le
    st.subheader("üíæ Sauvegarde du meilleur mod√®le")

    if st.button("Sauvegarder le meilleur mod√®le", type="primary"):
        try:
            best_model_name = max(results.keys(), key=lambda x: results[x]['auc_score'])
            best_model = models[best_model_name]

            model_data = {
                'model': best_model,
                'scaler': scaler,
                'model_name': best_model_name,
                'performance': results[best_model_name],
                'feature_names': df_processed.select_dtypes(include=[np.number]).drop(columns=['TDAH'], errors='ignore').columns.tolist(),
                'timestamp': datetime.now().isoformat()
            }

            joblib.dump(model_data, 'best_tdah_model.pkl')

            st.success(f"‚úÖ Mod√®le {best_model_name} sauvegard√© avec succ√®s!")
            st.balloons()

        except Exception as e:
            st.error(f"‚ùå Erreur lors de la sauvegarde : {str(e)}")

def page_prediction():
    """Page de pr√©diction avec IA"""
    st.markdown('<h1 class="main-header">üéØ Pr√©diction TDAH par IA</h1>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <h4>ü§ñ Pr√©diction par Intelligence Artificielle</h4>
    <p>Cette section utilise des mod√®les de machine learning entra√Æn√©s pour estimer
    la probabilit√© de TDAH bas√©e sur vos r√©ponses. Les r√©sultats sont √† des fins
    d'information uniquement et ne remplacent pas un diagnostic m√©dical.</p>
    </div>
    """, unsafe_allow_html=True)

    # Chargement du mod√®le sauvegard√©
    try:
        model_data = joblib.load('best_tdah_model.pkl')
        st.success(f"‚úÖ Mod√®le {model_data['model_name']} charg√©")

        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("Mod√®le", model_data['model_name'])
        with col2:
            st.metric("Accuracy", f"{model_data['performance']['accuracy']:.2%}")
        with col3:
            st.metric("AUC-ROC", f"{model_data['performance']['auc_score']:.3f}")

    except FileNotFoundError:
        st.warning("‚ö†Ô∏è Aucun mod√®le sauvegard√© trouv√©. Entra√Ænez d'abord un mod√®le dans la section Machine Learning.")

        # Entra√Ænement temporaire pour la d√©monstration
        df = load_data()
        if df is not None:
            df_processed, _ = advanced_preprocessing(df)
            if df_processed is not None and 'TDAH' in df_processed.columns:
                with st.spinner("Entra√Ænement d'un mod√®le temporaire..."):
                    results, models, scaler, _ = train_multiple_models(df_processed)
                    if results is not None:
                        best_model_name = max(results.keys(), key=lambda x: results[x]['auc_score'])
                        model_data = {
                            'model': models[best_model_name],
                            'scaler': scaler,
                            'model_name': best_model_name,
                            'performance': results[best_model_name],
                            'feature_names': df_processed.select_dtypes(include=[np.number]).drop(columns=['TDAH'], errors='ignore').columns.tolist()
                        }
                        st.success("‚úÖ Mod√®le temporaire cr√©√©")
                    else:
                        st.error("‚ùå Impossible de cr√©er un mod√®le")
                        return
            else:
                st.error("‚ùå Donn√©es non disponibles pour l'entra√Ænement")
                return
        else:
            st.error("‚ùå Impossible de charger les donn√©es")
            return

    # Interface de pr√©diction
    st.subheader("üìù Saisie des informations pour la pr√©diction")

    with st.form("prediction_form"):
        # Informations de base
        st.markdown("**Informations d√©mographiques**")
        col1, col2 = st.columns(2)

        with col1:
            age = st.number_input("√Çge", min_value=6, max_value=80, value=25)
            genre = st.selectbox("Genre", ["F√©minin", "Masculin"])

        with col2:
            niveau_etudes = st.selectbox("Niveau d'√©tudes",
                                       ["Primaire", "Coll√®ge", "Lyc√©e", "Universit√©", "Post-universitaire"])
            situation_pro = st.selectbox("Situation professionnelle",
                                       ["√âtudiant", "Employ√©", "Ind√©pendant", "Sans emploi", "Retrait√©"])

        # Scores comportementaux
        st.markdown("**Scores comportementaux (1-10, 10 = sympt√¥mes tr√®s pr√©sents)**")
        col1, col2, col3 = st.columns(3)

        with col1:
            inattention = st.slider("Score d'inattention", 1.0, 10.0, 5.0, 0.5,
                                  help="Difficult√©s de concentration, erreurs d'inattention, oublis")

        with col2:
            hyperactivite = st.slider("Score d'hyperactivit√©", 1.0, 10.0, 5.0, 0.5,
                                    help="Agitation motrice, difficult√© √† rester assis")

        with col3:
            impulsivite = st.slider("Score d'impulsivit√©", 1.0, 10.0, 5.0, 0.5,
                                  help="Interruptions, difficult√©s √† attendre, d√©cisions impulsives")

        # Facteurs contextuels
        st.markdown("**Facteurs contextuels (1-10)**")
        col1, col2 = st.columns(2)

        with col1:
            sommeil = st.slider("Probl√®mes de sommeil", 1.0, 10.0, 5.0, 0.5)
            anxiete = st.slider("Niveau d'anxi√©t√©", 1.0, 10.0, 5.0, 0.5)

        with col2:
            stress = st.slider("Niveau de stress", 1.0, 10.0, 5.0, 0.5)
            concentration = st.slider("Difficult√©s de concentration", 1.0, 10.0, 5.0, 0.5)

        # Ant√©c√©dents
        st.markdown("**Ant√©c√©dents**")
        col1, col2 = st.columns(2)

        with col1:
            antecedents_familiaux = st.selectbox("Ant√©c√©dents familiaux TDAH", ["Non", "Oui", "Incertain"])
            troubles_apprentissage = st.selectbox("Troubles d'apprentissage", ["Non", "Oui", "Incertain"])

        with col2:
            medicaments = st.selectbox("Prise de m√©dicaments psychotropes", ["Non", "Oui"])
            suivi_psy = st.selectbox("Suivi psychologique actuel", ["Non", "Oui"])

        predict_button = st.form_submit_button("üîÆ Effectuer la pr√©diction", type="primary")

    if predict_button:
        try:
            # Pr√©paration des donn√©es d'entr√©e
            # Encodage des variables cat√©gorielles
            genre_encoded = 1 if genre == "Masculin" else 0
            antecedents_encoded = 1 if antecedents_familiaux == "Oui" else 0

            # Cr√©ation du vecteur de features (adapt√© aux features du mod√®le)
            input_features = [
                age, genre_encoded, inattention, hyperactivite, impulsivite,
                sommeil, anxiete, stress, concentration, antecedents_encoded
            ]

            # Ajustement selon le nombre de features attendues
            expected_features = len(model_data.get('feature_names', input_features))

            # Compl√©ter ou tronquer selon les besoins
            while len(input_features) < expected_features:
                input_features.append(5.0)  # Valeur par d√©faut
            input_features = input_features[:expected_features]

            input_array = np.array(input_features).reshape(1, -1)

            # Normalisation si n√©cessaire
            if 'scaler' in model_data and model_data['scaler'] is not None:
                input_scaled = model_data['scaler'].transform(input_array)
            else:
                input_scaled = input_array

            # Pr√©diction
            model = model_data['model']
            prediction = model.predict(input_scaled)[0]
            prediction_proba = model.predict_proba(input_scaled)[0]

            # Affichage des r√©sultats
            st.success("üéØ Pr√©diction termin√©e!")

            # M√©triques principales
            col1, col2, col3 = st.columns(3)

            risk_percentage = prediction_proba[1] * 100

            with col1:
                st.metric(
                    "Probabilit√© TDAH",
                    f"{risk_percentage:.1f}%",
                    delta=f"{'√âlev√©' if risk_percentage > 60 else 'Mod√©r√©' if risk_percentage > 40 else 'Faible'}"
                )

            with col2:
                prediction_text = "TDAH Probable" if prediction == 1 else "TDAH Peu Probable"
                confidence = max(prediction_proba) * 100
                st.metric("Pr√©diction", prediction_text, f"Confiance: {confidence:.1f}%")

            with col3:
                st.metric("Mod√®le utilis√©", model_data['model_name'],
                         f"AUC: {model_data['performance']['auc_score']:.3f}")

            # Visualisation du risque
            st.subheader("üìä Visualisation du risque")

            # Gauge chart
            fig = go.Figure(go.Indicator(
                mode="gauge+number+delta",
                value=risk_percentage,
                domain={'x': [0, 1], 'y': [0, 1]},
                title={'text': "Probabilit√© de TDAH (%)"},
                delta={'reference': 50},
                gauge={
                    'axis': {'range': [None, 100]},
                    'bar': {'color': "#1976d2"},
                    'steps': [
                        {'range': [0, 30], 'color': "#c8e6c8"},
                        {'range': [30, 60], 'color': "#ffe0b2"},
                        {'range': [60, 80], 'color': "#ffcdd2"},
                        {'range': [80, 100], 'color': "#ffcdd2"}
                    ],
                    'threshold': {
                        'line': {'color': "red", 'width': 4},
                        'thickness': 0.75,
                        'value': 70
                    }
                }
            ))

            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)

            # Analyse des facteurs de risque
            st.subheader("üîç Analyse des facteurs")

            # Graphique radar des scores comportementaux
            categories = ['Inattention', 'Hyperactivit√©', 'Impulsivit√©', 'Sommeil', 'Anxi√©t√©', 'Stress']
            values = [inattention, hyperactivite, impulsivite, sommeil, anxiete, stress]

            fig = go.Figure()

            fig.add_trace(go.Scatterpolar(
                r=values,
                theta=categories,
                fill='toself',
                name='Vos scores',
                line_color='#1976d2'
            ))

            fig.add_trace(go.Scatterpolar(
                r=[5] * len(categories),
                theta=categories,
                fill='toself',
                name='Moyenne population',
                line_color='#ff7f0e',
                opacity=0.3
            ))

            fig.update_layout(
                polar=dict(
                    radialaxis=dict(
                        visible=True,
                        range=[0, 10]
                    )),
                showlegend=True,
                title="Profil comportemental",
                height=500
            )

            st.plotly_chart(fig, use_container_width=True)

            # Recommandations personnalis√©es
            st.subheader("üí° Recommandations personnalis√©es")

            if risk_percentage > 70:
                st.markdown("""
                <div class="warning-box">
                <h4>üî¥ Risque √©lev√© de TDAH d√©tect√©</h4>
                <p><strong>Recommandations urgentes :</strong></p>
                <ul>
                <li>üìû Consultez rapidement un professionnel de sant√© sp√©cialis√© (psychiatre, neurologue)</li>
                <li>üìã Demandez une √©valuation diagnostique compl√®te</li>
                <li>üìù Pr√©parez un historique d√©taill√© de vos sympt√¥mes</li>
                <li>üë• Informez votre entourage proche de vos difficult√©s</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

            elif risk_percentage > 40:
                st.markdown("""
                <div class="warning-box">
                <h4>üü° Risque mod√©r√© de TDAH</h4>
                <p><strong>Recommandations :</strong></p>
                <ul>
                <li>ü©∫ Consultez votre m√©decin traitant pour discuter de vos sympt√¥mes</li>
                <li>üìä Surveillez l'√©volution de vos difficult√©s</li>
                <li>üìö Documentez vos sympt√¥mes dans un journal</li>
                <li>üßò Explorez des strat√©gies de gestion du stress</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

            else:
                st.markdown("""
                <div class="success-box">
                <h4>üü¢ Risque faible de TDAH</h4>
                <p><strong>Informations :</strong></p>
                <ul>
                <li>‚úÖ Vos r√©ponses ne sugg√®rent pas la pr√©sence de TDAH</li>
                <li>üëÄ Continuez √† surveiller vos sympt√¥mes si vous avez des pr√©occupations</li>
                <li>üí™ Maintenez de bonnes habitudes de vie</li>
                <li>ü©∫ Consultez si les sympt√¥mes s'aggravent ou persistent</li>
                </ul>
                </div>
                """, unsafe_allow_html=True)

            # Facteurs de risque identifi√©s
            risk_factors = []
            if inattention >= 7:
                risk_factors.append("Score d'inattention √©lev√©")
            if hyperactivite >= 7:
                risk_factors.append("Score d'hyperactivit√© √©lev√©")
            if impulsivite >= 7:
                risk_factors.append("Score d'impulsivit√© √©lev√©")
            if antecedents_familiaux == "Oui":
                risk_factors.append("Ant√©c√©dents familiaux pr√©sents")
            if sommeil >= 7:
                risk_factors.append("Probl√®mes de sommeil importants")

            if risk_factors:
                st.markdown("**‚ö†Ô∏è Facteurs de risque identifi√©s :**")
                for factor in risk_factors:
                    st.write(f"‚Ä¢ {factor}")

        except Exception as e:
            st.error(f"‚ùå Erreur lors de la pr√©diction : {str(e)}")
            st.info("üí° V√©rifiez que le mod√®le est correctement entra√Æn√© dans la section Machine Learning.")

def page_test_asrs():
    """Page de test ASRS-v1.1 complet"""
    st.markdown('<h1 class="main-header">üìù Test ASRS-v1.1 Officiel</h1>', unsafe_allow_html=True)

    st.markdown("""
    <div class="info-box">
    <h4>üîç √Ä propos du test ASRS-v1.1</h4>
    <p>L'Adult ADHD Self-Report Scale (ASRS-v1.1) est l'outil de d√©pistage de r√©f√©rence
    d√©velopp√© par l'Organisation Mondiale de la Sant√© en collaboration avec Harvard Medical School.
    Il comprend 18 questions bas√©es sur les crit√®res DSM-5 pour le TDAH chez l'adulte.</p>
    </div>
    """, unsafe_allow_html=True)

    # Questions ASRS-v1.1 compl√®tes (version fran√ßaise officielle)
    questions_part_a = {
        1: "√Ä quelle fr√©quence avez-vous du mal √† terminer les d√©tails finaux d'un projet, une fois que les parties difficiles ont √©t√© faites ?",
        2: "√Ä quelle fr√©quence avez-vous des difficult√©s √† mettre les choses en ordre quand vous devez faire une t√¢che qui n√©cessite de l'organisation ?",
        3: "√Ä quelle fr√©quence avez-vous des probl√®mes pour vous rappeler des rendez-vous ou des obligations ?",
        4: "Quand vous avez une t√¢che qui demande beaucoup de r√©flexion, √† quelle fr√©quence √©vitez-vous ou retardez-vous de commencer ?",
        5: "√Ä quelle fr√©quence bougez-vous ou vous agitez-vous avec vos mains ou vos pieds quand vous devez rester assis longtemps ?",
        6: "√Ä quelle fr√©quence vous sentez-vous trop actif et oblig√© de faire des choses, comme si vous √©tiez men√© par un moteur ?"
    }

    questions_part_b = {
        7: "√Ä quelle fr√©quence faites-vous des erreurs d'inattention quand vous devez travailler sur un projet ennuyeux ou difficile ?",
        8: "√Ä quelle fr√©quence avez-vous des difficult√©s √† maintenir votre attention quand vous faites un travail ennuyeux ou r√©p√©titif ?",
        9: "√Ä quelle fr√©quence avez-vous des difficult√©s √† vous concentrer sur ce que les gens vous disent, m√™me quand ils vous parlent directement ?",
        10: "√Ä quelle fr√©quence √©garez-vous ou avez des difficult√©s √† trouver des choses √† la maison ou au travail ?",
        11: "√Ä quelle fr√©quence √™tes-vous distrait par l'activit√© ou le bruit autour de vous ?",
        12: "√Ä quelle fr√©quence quittez-vous votre si√®ge dans des r√©unions ou d'autres situations o√π vous √™tes suppos√© rester assis ?",
        13: "√Ä quelle fr√©quence vous sentez-vous agit√© ou nerveux ?",
        14: "√Ä quelle fr√©quence avez-vous des difficult√©s √† vous d√©tendre quand vous avez du temps libre ?",
        15: "√Ä quelle fr√©quence vous trouvez-vous en train de trop parler dans des situations sociales ?",
        16: "Quand vous √™tes en conversation, √† quelle fr√©quence vous surprenez-vous √† finir les phrases des personnes √† qui vous parlez, avant qu'elles puissent les finir elles-m√™mes ?",
        17: "√Ä quelle fr√©quence avez-vous des difficult√©s √† attendre votre tour dans des situations o√π chacun doit attendre son tour ?",
        18: "√Ä quelle fr√©quence interrompez-vous les autres quand ils sont occup√©s ?"
    }

    # Options de r√©ponse
    options = ["Jamais", "Rarement", "Parfois", "Souvent", "Tr√®s souvent"]

    # Initialisation des r√©ponses dans le session state
    if 'asrs_responses' not in st.session_state:
        st.session_state.asrs_responses = {}

    # Formulaire de questionnaire
    with st.form("asrs_questionnaire"):
        # Part A - Questions de d√©pistage
        st.markdown('<h3 style="color: #1976d2;">üìã Partie A - Questions de d√©pistage principales</h3>', unsafe_allow_html=True)
        st.markdown("*Ces 6 questions sont les plus pr√©dictives du TDAH selon les recherches de l'OMS*")

        for q_num, text in questions_part_a.items():
            st.session_state.asrs_responses[q_num] = st.radio(
                f"**Question {q_num}:** {text}",
                options=options,
                index=0,  # "Jamais" par d√©faut
                key=f"q{q_num}",
                help="Choisissez la fr√©quence qui correspond le mieux √† votre exp√©rience"
            )

        st.markdown("---")

        # Part B - Questions compl√©mentaires
        st.markdown('<h3 style="color: #1976d2;">üìã Partie B - Questions compl√©mentaires</h3>', unsafe_allow_html=True)
        st.markdown("*Ces questions permettent une √©valuation plus compl√®te des sympt√¥mes*")

        for q_num, text in questions_part_b.items():
            st.session_state.asrs_responses[q_num] = st.radio(
                f"**Question {q_num}:** {text}",
                options=options,
                index=0,  # "Jamais" par d√©faut
                key=f"q{q_num}",
                help="Choisissez la fr√©quence qui correspond le mieux √† votre exp√©rience"
            )

        submitted = st.form_submit_button("üîç Calculer mon score ASRS", type="primary")

    if submitted:
        # V√©rification que toutes les questions ont une r√©ponse
        if len(st.session_state.asrs_responses) < 18:
            st.error("‚ùå Veuillez r√©pondre √† toutes les questions avant de calculer le score.")
            return

        # Calcul des scores selon les crit√®res officiels ASRS
        score_mapping = {"Jamais": 0, "Rarement": 1, "Parfois": 2, "Souvent": 3, "Tr√®s souvent": 4}

        # Scores par partie
        part_a_scores = [score_mapping[st.session_state.asrs_responses[i]] for i in range(1, 7)]
        part_a_total = sum(part_a_scores)

        part_b_scores = [score_mapping[st.session_state.asrs_responses[i]] for i in range(7, 19)]
        part_b_total = sum(part_b_scores)

        total_score = part_a_total + part_b_total

        # Crit√®res de d√©pistage positif pour Part A (selon recherches OMS)
        # Seuils sp√©cifiques par question pour Part A
        part_a_thresholds = [2, 2, 2, 2, 2, 2]  # Seuils cliniques valid√©s
        part_a_positive = sum([1 for i, score in enumerate(part_a_scores) if score >= part_a_thresholds[i]])

        # Analyse par domaine (Inattention vs Hyperactivit√©/Impulsivit√©)
        inattention_questions = [1, 2, 3, 4, 7, 8, 9, 10, 11]
        hyperactivity_questions = [5, 6, 12, 13, 14, 15, 16, 17, 18]

        inattention_score = sum([score_mapping[st.session_state.asrs_responses[i]] for i in inattention_questions])
        hyperactivity_score = sum([score_mapping[st.session_state.asrs_responses[i]] for i in hyperactivity_questions])

        # Affichage des r√©sultats
        st.success("‚úÖ Questionnaire ASRS-v1.1 compl√©t√©!")

        # M√©triques principales
        col1, col2, col3, col4 = st.columns(4)

        with col1:
            st.metric("Score Partie A", f"{part_a_total}/24", f"{part_a_positive}/6 crit√®res positifs")

        with col2:
            st.metric("Score Partie B", f"{part_b_total}/48")

        with col3:
            st.metric("Score Total", f"{total_score}/72", f"{(total_score/72)*100:.1f}%")

        with col4:
            risk_level = "√âlev√©" if part_a_positive >= 4 else "Mod√©r√©" if part_a_positive >= 2 else "Faible"
            st.metric("Niveau de risque", risk_level)

        # Interpr√©tation clinique officielle
        st.subheader("üéØ Interpr√©tation clinique")

        if part_a_positive >= 4:
            st.markdown("""
            <div class="warning-box">
            <h4>üî¥ D√©pistage POSITIF - Sympt√¥mes hautement compatibles avec un TDAH</h4>
            <p><strong>Signification clinique :</strong> Vos r√©ponses √† la Partie A indiquent une forte probabilit√©
            de pr√©sence de sympt√¥mes TDAH selon les crit√®res de l'OMS.</p>

            <p><strong>Recommandations urgentes :</strong></p>
            <ul>
            <li>üìû <strong>Consultez rapidement un professionnel de sant√© sp√©cialis√©</strong> (psychiatre, neurologue, m√©decin form√© au TDAH)</li>
            <li>üìã Demandez une √©valuation diagnostique compl√®te incluant entretien clinique et tests neuropsychologiques</li>
            <li>üìù Pr√©parez un historique d√©taill√© de vos sympt√¥mes depuis l'enfance</li>
            <li>üë• Contactez des associations de patients TDAH pour support et information</li>
            </ul>

            <p><strong>‚ö†Ô∏è Important :</strong> Ce test de d√©pistage ne constitue pas un diagnostic.
            Seul un professionnel de sant√© qualifi√© peut poser un diagnostic de TDAH.</p>
            </div>
            """, unsafe_allow_html=True)

        elif part_a_positive >= 2:
            st.markdown("""
            <div class="warning-box">
            <h4>üü° D√©pistage MOD√âR√â - Certains sympt√¥mes TDAH pr√©sents</h4>
            <p><strong>Signification clinique :</strong> Vos r√©ponses sugg√®rent la pr√©sence de certains sympt√¥mes
            compatibles avec le TDAH, n√©cessitant une attention particuli√®re.</p>

            <p><strong>Recommandations :</strong></p>
            <ul>
            <li>ü©∫ Consultez votre m√©decin traitant pour discuter de vos pr√©occupations</li>
            <li>üìä Surveillez l'√©volution de vos sympt√¥mes sur plusieurs semaines</li>
            <li>üìö Tenez un journal de vos difficult√©s quotidiennes</li>
            <li>üßò Explorez des strat√©gies de gestion des sympt√¥mes (organisation, mindfulness)</li>
            <li>üë• Consid√©rez un suivi sp√©cialis√© si les sympt√¥mes persistent ou s'aggravent</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

        else:
            st.markdown("""
            <div class="success-box">
            <h4>üü¢ D√©pistage N√âGATIF - Peu de sympt√¥mes TDAH d√©tect√©s</h4>
            <p><strong>Signification clinique :</strong> Vos r√©ponses ne sugg√®rent pas la pr√©sence
            de sympt√¥mes TDAH significatifs selon les crit√®res de d√©pistage de l'OMS.</p>

            <p><strong>Informations importantes :</strong></p>
            <ul>
            <li>‚úÖ Vos difficult√©s actuelles peuvent avoir d'autres causes (stress, fatigue, autres troubles)</li>
            <li>üëÄ Continuez √† surveiller vos sympt√¥mes - le TDAH peut se manifester diff√©remment selon les p√©riodes</li>
            <li>üí™ Maintenez de bonnes habitudes de vie (sommeil, exercice, organisation)</li>
            <li>ü©∫ N'h√©sitez pas √† consulter si vous avez d'autres pr√©occupations de sant√© mentale</li>
            </ul>
            </div>
            """, unsafe_allow_html=True)

        # Visualisations d√©taill√©es
        st.subheader("üìä Analyse d√©taill√©e de vos r√©ponses")

        # Graphique des scores par domaine
        col1, col2 = st.columns(2)

        with col1:
            domains_df = pd.DataFrame({
                'Domaine': ['Inattention', 'Hyperactivit√©/Impulsivit√©'],
                'Score': [inattention_score, hyperactivity_score],
                'Score_Max': [36, 36],  # 9 questions * 4 points max chacune
                'Pourcentage': [
                    (inattention_score / 36) * 100,
                    (hyperactivity_score / 36) * 100
                ]
            })

            fig = px.bar(domains_df, x='Domaine', y='Pourcentage',
                        title="R√©partition des sympt√¥mes par domaine (%)",
                        color='Pourcentage',
                        color_continuous_scale='RdYlBu_r',
                        text='Pourcentage')
            fig.update_traces(texttemplate='%{text:.1f}%', textposition='outside')
            fig.update_layout(height=400, yaxis_range=[0, 100])
            st.plotly_chart(fig, use_container_width=True)

        with col2:
            # R√©partition des r√©ponses par fr√©quence
            response_counts = pd.Series(list(st.session_state.asrs_responses.values())).value_counts()

            fig = px.pie(values=response_counts.values, names=response_counts.index,
                        title="R√©partition de vos r√©ponses par fr√©quence",
                        color_discrete_sequence=px.colors.qualitative.Set3)
            fig.update_layout(height=400)
            st.plotly_chart(fig, use_container_width=True)

        # Graphique radar d√©taill√©
        st.subheader("üéØ Profil d√©taill√© des sympt√¥mes")

        # Regroupement des questions par th√®me
        themes = {
            'Organisation': [1, 2, 10],
            'Attention soutenue': [7, 8, 9, 11],
            'M√©moire': [3],
            'Procrastination': [4],
            'Hyperactivit√© motrice': [5, 12],
            'Hyperactivit√© mentale': [6, 13, 14],
            'Impulsivit√© verbale': [15, 16],
            'Impulsivit√© comportementale': [17, 18]
        }

        theme_scores = {}
        for theme, questions in themes.items():
            scores = [score_mapping[st.session_state.asrs_responses[q]] for q in questions]
            theme_scores[theme] = np.mean(scores)

        fig = go.Figure()

        fig.add_trace(go.Scatterpolar(
            r=list(theme_scores.values()),
            theta=list(theme_scores.keys()),
            fill='toself',
            name='Vos scores',
            line_color='#1976d2'
        ))

        fig.add_trace(go.Scatterpolar(
            r=[2] * len(theme_scores),  # Seuil moyen
            theta=list(theme_scores.keys()),
            fill='toself',
            name='Seuil de pr√©occupation',
            line_color='#ff7f0e',
            opacity=0.3
        ))

        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, 4],
                    tickvals=[0, 1, 2, 3, 4],
                    ticktext=['Jamais', 'Rarement', 'Parfois', 'Souvent', 'Tr√®s souvent']
                )),
            showlegend=True,
            title="Profil d√©taill√© par domaine de sympt√¥mes",
            height=600
        )

        st.plotly_chart(fig, use_container_width=True)

        # Recommandations sp√©cifiques par domaine
        st.subheader("üí° Recommandations sp√©cifiques")

        high_score_domains = [domain for domain, score in theme_scores.items() if score >= 2.5]

        if high_score_domains:
            st.markdown("**Domaines n√©cessitant une attention particuli√®re :**")

            recommendations = {
                'Organisation': "üìã Utilisez des outils d'organisation (agenda, listes, applications), cr√©ez des routines structur√©es",
                'Attention soutenue': "üéØ Pratiquez des exercices de mindfulness, √©liminez les distractions, prenez des pauses r√©guli√®res",
                'M√©moire': "üìù Utilisez des rappels, notez tout, cr√©ez des associations visuelles",
                'Procrastination': "‚è∞ D√©coupez les t√¢ches en √©tapes, utilisez la technique Pomodoro, fixez des √©ch√©ances",
                'Hyperactivit√© motrice': "üèÉ‚Äç‚ôÇÔ∏è Int√©grez de l'exercice physique r√©gulier, utilisez des objets anti-stress",
                'Hyperactivit√© mentale': "üßò Pratiquez la m√©ditation, apprenez des techniques de relaxation",
                'Impulsivit√© verbale': "ü§ê Pratiquez l'√©coute active, comptez jusqu'√† 3 avant de parler",
                'Impulsivit√© comportementale': "‚è∏Ô∏è D√©veloppez des strat√©gies de pause, r√©fl√©chissez avant d'agir"
            }

            for domain in high_score_domains:
                if domain in recommendations:
                    st.write(f"‚Ä¢ **{domain}** : {recommendations[domain]}")

        # Export des r√©sultats
        st.subheader("üíæ Sauvegarde de vos r√©sultats")

        if st.button("üìÑ G√©n√©rer un rapport PDF", type="secondary"):
            # Cr√©ation d'un rapport simple en text
            report_text = f"""
RAPPORT DE D√âPISTAGE TDAH - ASRS-v1.1
=====================================

Date: {datetime.now().strftime('%d/%m/%Y %H:%M')}

SCORES:
- Partie A: {part_a_total}/24 ({part_a_positive}/6 crit√®res positifs)
- Partie B: {part_b_total}/48
- Score Total: {total_score}/72 ({(total_score/72)*100:.1f}%)

INTERPR√âTATION:
- Niveau de risque: {risk_level}
- Domaine Inattention: {inattention_score}/36 ({(inattention_score/36)*100:.1f}%)
- Domaine Hyperactivit√©/Impulsivit√©: {hyperactivity_score}/36 ({(hyperactivity_score/36)*100:.1f}%)

RECOMMANDATION:
{"Consultation sp√©cialis√©e recommand√©e" if part_a_positive >= 4 else "Surveillance et consultation si sympt√¥mes persistent" if part_a_positive >= 2 else "Pas d'indication de TDAH selon ce d√©pistage"}

IMPORTANT: Ce d√©pistage ne remplace pas un diagnostic m√©dical professionnel.
            """

            st.download_button(
                label="T√©l√©charger le rapport",
                data=report_text,
                file_name=f"rapport_asrs_{datetime.now().strftime('%Y%m%d_%H%M')}.txt",
                mime="text/plain"
            )

# =================== NAVIGATION PRINCIPALE ===================

def main():
    """Fonction principale avec navigation"""

    # Sidebar avec style am√©lior√©
    st.sidebar.markdown("""
    <div style="text-align: center; padding: 1.5rem; background: linear-gradient(145deg, #e3f2fd, #bbdefb); border-radius: 10px; margin-bottom: 1rem;">
        <h1 style="color: #1976d2; margin-bottom: 0.5rem;">üß† TDAH</h1>
        <p style="color: #1565c0; font-size: 1rem; margin-bottom: 0;">D√©pistage & IA Avanc√©e</p>
    </div>
    """, unsafe_allow_html=True)

    # Menu de navigation
    pages = {
        "üè† Accueil": page_accueil,
        "üìä Exploration des Donn√©es": page_exploration,
        "ü§ñ Machine Learning": page_machine_learning,
        "üéØ Pr√©diction IA": page_prediction,
        "üìù Test ASRS-v1.1": page_test_asrs
    }

    selected_page = st.sidebar.selectbox(
        "Navigation",
        list(pages.keys()),
        help="S√©lectionnez la section que vous souhaitez explorer"
    )

    # Informations sur les donn√©es dans la sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("**üìä Informations syst√®me**")

    # Test de chargement des donn√©es
    df = load_data()
    if df is not None and not df.empty:
        st.sidebar.success("‚úÖ Donn√©es charg√©es")
        st.sidebar.info(f"üìà {len(df)} √©chantillons")
        st.sidebar.info(f"üìã {len(df.columns)} variables")

        if 'TDAH' in df.columns:
            tdah_count = (df['TDAH'] == 'Oui').sum()
            st.sidebar.info(f"üéØ {tdah_count} cas TDAH")
    else:
        st.sidebar.error("‚ùå Donn√©es non disponibles")

    # Informations sur les mod√®les
    try:
        model_data = joblib.load('best_tdah_model.pkl')
        st.sidebar.success("ü§ñ Mod√®le IA disponible")
        st.sidebar.info(f"üèÜ {model_data['model_name']}")
    except FileNotFoundError:
        st.sidebar.warning("‚ö†Ô∏è Mod√®le IA non entra√Æn√©")

    # Footer de la sidebar
    st.sidebar.markdown("---")
    st.sidebar.markdown("""
    <div style="text-align: center; font-size: 0.8rem; color: #666;">
    <p>‚ö†Ô∏è Outil de recherche uniquement<br>
    Ne remplace pas un diagnostic m√©dical</p>
    </div>
    """, unsafe_allow_html=True)

    # Affichage de la page s√©lectionn√©e
    try:
        pages[selected_page]()
    except Exception as e:
        st.error(f"‚ùå Erreur lors du chargement de la page : {str(e)}")
        st.info("üí° Essayez de recharger la page ou s√©lectionnez une autre section.")

# =================== LANCEMENT DE L'APPLICATION ===================

if __name__ == "__main__":
    main()
